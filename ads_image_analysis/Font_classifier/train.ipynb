{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import HENetdataset\n",
    "from dataset.transformation import augmenter, to_tensor\n",
    "from model.lightning_wraper import HENetWrapper\n",
    "from model.henet import HENet\n",
    "\n",
    "import os \n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    ModelSummary,\n",
    "    StochasticWeightAveraging\n",
    ")\n",
    "from model.configs import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"./configs/train_cfg.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"F:/tfont/\"\n",
    "img_list = os.listdir(dataset_path) \n",
    "img_paths = []\n",
    "for img in img_list:\n",
    "    img_paths.append(dataset_path + img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split data\n",
    "\n",
    "train_ratio = config['training']['train_ratio']\n",
    "test_ratio = config['training']['test_ratio']\n",
    "\n",
    "\n",
    "\n",
    "random.shuffle(img_paths) \n",
    "\n",
    "total_size = len(img_paths)\n",
    "train_size = int(train_ratio*total_size)\n",
    "test_size  = int(test_ratio*total_size) \n",
    "valid_size =  total_size - train_size - test_size\n",
    "\n",
    "train_data = img_paths[:train_size]\n",
    "test_data  = img_paths[train_size:train_size + test_size]\n",
    "valid_data = img_paths[train_size + test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch dataset\n",
    "train_dataset =  HENetdataset(img_paths  = train_data, transform=augmenter)\n",
    "test_dataset  =  HENetdataset(img_paths  = test_data,  transform=to_tensor)\n",
    "valid_dataset =  HENetdataset(img_paths  = valid_data, transform=to_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader \n",
    "batch_size = config['training']['batch_size']\n",
    "pwf = False\n",
    "pwt = True\n",
    "train_loader =  DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers= 8,  persistent_workers= pwt)\n",
    "\n",
    "valid_loader =  DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers= 8,  persistent_workers= pwf)\n",
    "\n",
    "test_loader  =  DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers= 8,  persistent_workers= pwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "n_classes = config['training']['n_classes']\n",
    "lr = config['training']['learning_rate']\n",
    "\n",
    "model = HENetWrapper(model=HENet(n_classes=n_classes),\n",
    "                     num_classes=n_classes,\n",
    "                     learning_rate=lr\n",
    "                     )\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trainer \n",
    "\n",
    "training_callbacks = [\n",
    "        EarlyStopping(monitor=\"val_loss\", mode=\"min\"),\n",
    "        StochasticWeightAveraging(swa_lrs=1e-2),\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "        ModelCheckpoint(\n",
    "            dirpath=\"./output\",\n",
    "            save_top_k=config['training']['k'],\n",
    "            monitor=\"val_loss\",\n",
    "            filename=\"HENet-{epoch:02d}-{val_loss:.4f}-{val_accuracy:.4f}\",\n",
    "            save_last=True,\n",
    "        ),\n",
    "        ModelSummary(-1)\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer = L.Trainer(max_epochs=40, callbacks=training_callbacks)\n",
    "\n",
    "\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=valid_loader,\n",
    "    ckpt_path= None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test_loader) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
